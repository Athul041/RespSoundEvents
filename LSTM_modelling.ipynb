{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import os\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset_folder = '../HF_Lung_V1'\n",
    "train_data_path = os.path.join(dataset_folder, 'train')\n",
    "test_data_path = os.path.join(dataset_folder, 'test')\n",
    "\n",
    "SAMPLE_RATE = 4000\n",
    "ALL_LABELS = ['I', 'D', 'E', 'Rhonchi', 'Wheeze', 'Stridor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungDataSet(Dataset):\n",
    "    def __init__(self, file_list, transform, targets_transform):\n",
    "        self.file_list = file_list\n",
    "        self.target_transform = targets_transform\n",
    "        self.target_sample_rate = SAMPLE_RATE\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        labels = self.__get_audio_sample_labels(index)\n",
    "\n",
    "        # Read Audio from path\n",
    "        wav, sample_rate = librosa.load(audio_sample_path, sr=None, mono=False)\n",
    "        cutoff_freq = 80\n",
    "\n",
    "        # Apply high pass filter cutoff = 80Hz, filter order = 10\n",
    "        b, a = signal.butter(N=10, Wn=cutoff_freq,\n",
    "                             btype='high', fs=sample_rate)\n",
    "        wav_filtered = signal.filtfilt(b, a, wav)\n",
    "\n",
    "        # Convert the np array to torch tensor and transfer to device\n",
    "        torch_signal = torch.tensor(wav_filtered.copy()).reshape(1, -1)\n",
    "\n",
    "        # Resample the signal to 4kHz\n",
    "        torch_signal = self._resample_if_necessary(torch_signal, sample_rate)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            torch_signal = self.transform(torch_signal)\n",
    "        if self.target_transform:\n",
    "            labels = self.target_transform(torch_signal, sample_rate, labels)\n",
    "\n",
    "        return torch_signal, labels\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        path = os.path.join(self.file_list[index] + \".wav\")\n",
    "        return path\n",
    "\n",
    "    def __get_audio_sample_labels(self, index):\n",
    "        path = os.path.join(self.file_list[index] + \"_label.txt\")\n",
    "        labels = pd.read_csv(path, sep=' ', header=None,\n",
    "                             names=[\"class\", \"start\", \"end\"])\n",
    "        labels['start'] = pd.to_timedelta(labels['start']).dt.total_seconds()\n",
    "        labels['end'] = pd.to_timedelta(labels['end']).dt.total_seconds()\n",
    "        return labels\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(\n",
    "                sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)\n",
    "    print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dimensions, hidden_layers, output_dimensions, device=\"cpu\"):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.num_lstm_layers = len(hidden_layers)\n",
    "        self.model = nn.Sequential()\n",
    "        in_num = input_dimensions\n",
    "        for i in range(self.num_lstm_layers):\n",
    "            out_num = hidden_layers[i]\n",
    "            layer = nn.LSTMCell(in_num, out_num)\n",
    "            self.model.add_module('LSTM_%d'%i, layer)\n",
    "            # LSTMCell by default has an activation function of tanh in the layer \n",
    "            in_num = out_num\n",
    "        # end with a linear layer\n",
    "        layer = nn.Linear(in_num, output_dimensions)\n",
    "        self.model.add_module('Linear_end', layer)\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        # num samples refers to the batch size, not the length of the sequence\n",
    "        num_samples = x.shape[0]\n",
    "        # For general NN, the forward function was all about calling the sequential object we defined in the constructor.\n",
    "        # Now, we need to be more careful about what we feed into the RNN/LSTM layers.\n",
    "        # Recurrent layers require the latent state of their cells\n",
    "\n",
    "        # We need to initialize the cell state c,\n",
    "        # and hidden state h\n",
    "        # for every layer.\n",
    "        # pytorch does this would like us to initialize this the same size as the input (num_samples)\n",
    "        h_t = {}\n",
    "        c_t = {}\n",
    "        for i in range(self.num_lstm_layers):\n",
    "            h_t[i] = torch.zeros(num_samples, self.hidden_layers[i], dtype=torch.float32).to(self.device)\n",
    "            c_t[i] = torch.zeros(num_samples, self.hidden_layers[i], dtype=torch.float32).to(self.device)\n",
    "        # dim = time dimension\n",
    "        for input_t in x.split(1, dim=2):\n",
    "            for i in range(self.num_lstm_layers):\n",
    "                module = self.model._modules['LSTM_%d'%i]\n",
    "                if i == 0:\n",
    "                    input_t = input_t.squeeze().to(self.device)\n",
    "                    h_t[i], c_t[i] = module(input_t, (h_t[i], c_t[i]))\n",
    "                else:\n",
    "                    h_t[i], c_t[i] = module(h_t[i-1], (h_t[i], c_t[i]))\n",
    "            # pass the hidden state along the the linear layer\n",
    "            module = self.model._modules['Linear_end']\n",
    "            output = module(h_t[i])\n",
    "            outputs.append(output)\n",
    "        \n",
    "        # Change outputs to tensor\n",
    "        outputs = torch.stack(outputs, dim=0)\n",
    "        return outputs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_1(nn.Module):\n",
    "    def __init__(self, input_dimensions, n_hidden, output_dimensions, n_layers=1, drop_prob=0, bidirectional=False, device=\"cpu\"):\n",
    "        super(Net_1, self).__init__()\n",
    "        \n",
    "        self.n_features = input_dimensions\n",
    "        self.n_hidden_units = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        self.bidirectional = bidirectional,\n",
    "        self.n_out = output_dimensions\n",
    "        self.device = device\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.n_features,\n",
    "                            hidden_size=self.n_hidden_units,\n",
    "                            num_layers=self.n_layers,\n",
    "                            dropout=self.drop_prob,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=False)\n",
    "\n",
    "        # self.dropout = nn.Dropout(self.drop_prob)\n",
    "\n",
    "        self.dense = nn.Linear(\n",
    "            in_features=self.n_hidden_units, out_features=self.n_out)\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        self.network = nn.Sequential(self.lstm,\n",
    "                                     self.dense,\n",
    "                                     self.activation)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"x \", x.shape)\n",
    "        h_0 = torch.zeros(self.n_layers, x.shape[0], self.n_hidden_units).to(self.device)\n",
    "        # print(\"h_0 \", h_0.shape)\n",
    "        c_0 = torch.zeros(self.n_layers, x.shape[0], self.n_hidden_units).to(self.device)\n",
    "        output, (h_t, c_t) = self.lstm(x, (h_0, c_0))\n",
    "        # print(\"output\", output.shape)\n",
    "        output = self.dense(output)\n",
    "        output = self.activation(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingLayerWise(num_epochs, model, optimizer, scheduler, loss_fn, train_loader, test_loader, device):\n",
    "    model.train()\n",
    "    training_losses   = []\n",
    "    training_accuracy = []\n",
    "    testing_losses    = []\n",
    "    testing_accuracy  = []\n",
    "    for e in range(num_epochs):\n",
    "        train_batch_loss        = []\n",
    "        testing_batch_loss      = []\n",
    "        train_batch_accuracy    = []\n",
    "        testing_batch_accuracy  = []\n",
    "        # update weights using training data\n",
    "        for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "            # print(data.shape)\n",
    "            optimizer.zero_grad()\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # data is (batch_size x 40 x number of frames)\n",
    "            out = model(data)\n",
    "            # out returns a class prediction for every sample of our sequence for each batch\n",
    "            # [TIME, batch, num_output_classes]\n",
    "            # we only want to perform backpropagation for what we think it is at the end of the sequence\n",
    "            # out = out[-1,:,:].squeeze()\n",
    "            loss = loss_fn(out, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # keep track of the loss\n",
    "\n",
    "            pred = out.detach().cpu().numpy()\n",
    "            accuracy = sum(pred == labels.detach().cpu().numpy())/train_loader.batch_size\n",
    "            train_batch_loss.append(loss.item())\n",
    "            train_batch_accuracy.append(accuracy)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # see how classifying ahead looks on the test data\n",
    "            # just do the same thing without loss.backward()\n",
    "            for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                labels = labels.to(device)\n",
    "                out = model(data)\n",
    "                out = out[-1,:,:].squeeze()\n",
    "                loss = loss_fn(out, labels)\n",
    "                pred = out.detach().cpu().numpy()\n",
    "                accuracy = sum(pred == labels.detach().cpu().numpy())/train_loader.batch_size\n",
    "                testing_batch_loss.append(loss.item())\n",
    "                testing_batch_accuracy.append(accuracy)\n",
    "            # usually you run step on the validation loss (when using reduceLRonPlateau),\n",
    "            # but this example does not use a validation set, and we are running StepLR as our scheduler\n",
    "            scheduler.step()\n",
    "        \n",
    "        training_losses.append(sum(train_batch_loss)/len(train_batch_loss))\n",
    "        testing_losses.append(sum(testing_batch_loss)/len(testing_batch_loss))\n",
    "        training_accuracy.append(sum(train_batch_accuracy)/len(train_batch_accuracy))\n",
    "        testing_accuracy.append(sum(testing_batch_accuracy)/len(testing_batch_accuracy))\n",
    "            \n",
    "        # print out epoch metrics\n",
    "        print('-'*15)\n",
    "\n",
    "        print(\"Epoch: {}:\".format(e+1))\n",
    "        print(\"\\t train loss: {:.2f}, test loss: {:.2f}\".format(training_losses[-1], testing_losses[-1]))\n",
    "        print(\"\\t train accuracy: {:.2f}, test accuracy: {:.2f}\".format(training_accuracy[-1], testing_accuracy[-1]))\n",
    "\n",
    "    return training_losses, testing_losses, training_accuracy, testing_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # A data tuple has the form:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "    tensors, targets = [], []\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, label in batch:\n",
    "        tensors += [waveform]\n",
    "        targets += [torch.tensor(label, dtype=torch.float)]\n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = [item.squeeze().t().float() for item in tensors]\n",
    "    tensors = torch.stack(tensors)\n",
    "    targets = torch.stack(targets)\n",
    "    # print(\"batch \", tensors.shape)\n",
    "    return tensors, targets\n",
    "\n",
    "def create_dataloader(train_data, batch_size):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, num_workers=4, pin_memory=True, collate_fn=collate_fn)\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 0 has been set.\n",
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "list_files = []\n",
    "data_folder = train_data_path\n",
    "for file in os.listdir(data_folder):\n",
    "    if file.endswith(\".wav\"):\n",
    "        list_files.append(os.path.join(data_folder, os.path.splitext(file)[0]))\n",
    "        \n",
    "window_function = torch.hamming_window\n",
    "window_length = 256\n",
    "hop_length = 64\n",
    "n_bands = 256\n",
    "spectrogram = torchaudio.transforms.Spectrogram(\n",
    "    # sample_rate=SAMPLE_RATE,\n",
    "    n_fft=256,\n",
    "    win_length=window_length,\n",
    "    hop_length=hop_length,\n",
    "    window_fn=window_function\n",
    ")\n",
    "\n",
    "def label_encoder(torch_signal, sample_rate, labels):\n",
    "    windows = torch_signal.shape[-1]\n",
    "    labels_array = np.zeros([windows, len(ALL_LABELS)])\n",
    "    start = 0\n",
    "    end = 15*sample_rate\n",
    "    window_size = np.ceil((end - start)/windows)\n",
    "    for i in range(windows):\n",
    "        win_start = i*window_size + start\n",
    "        win_end = win_start + window_size\n",
    "        for index, row in labels.iterrows():\n",
    "            row_start = row['start']*sample_rate\n",
    "            row_end = row['end']*sample_rate\n",
    "            if (row_start <= win_start) and (row_end >= win_end):\n",
    "                labels_array[i][ALL_LABELS.index(row['class'])] = 1\n",
    "    return labels_array\n",
    "\n",
    "set_random_seeds(0)\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device {device}\")\n",
    "dataset = LungDataSet(list_files, transform=spectrogram,\n",
    "                      targets_transform=label_encoder)\n",
    "train_dataset = Subset(dataset=dataset, indices=range(0, np.floor(len(dataset)*0.8).astype(int)))\n",
    "test_dataset = Subset(dataset=dataset, indices=range(np.floor(len(dataset)*0.8).astype(int), len(dataset)))\n",
    "\n",
    "# seed = 0\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = create_dataloader(train_dataset, batch_size)\n",
    "test_loader = create_dataloader(test_dataset, batch_size)\n",
    "\n",
    "# net = Net(num_recurrent_layers=1, num_input_features=201, hidden_layer_nodes=32, output_feature_nums=len(ALL_LABELS))\n",
    "\n",
    "num_windows = np.ceil(15*SAMPLE_RATE/hop_length)\n",
    "num_features = n_bands//2 + 1\n",
    "hidden_layers = 64\n",
    "# output_dimensions = len(label_dict)\n",
    "model = Net_1(input_dimensions=num_features, n_hidden=hidden_layers, output_dimensions=len(ALL_LABELS), n_layers=1, drop_prob=0, bidirectional=False, device=device)\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "# We are performing classification -> use crossentropy\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer= optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# Use a scheduler to reduce learning rate by 1/2 every 20 epochs\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # reduce the learning after\n",
    "\n",
    "training_losses, testing_losses, training_accuracy, testing_accuracy = trainingLayerWise(num_epochs, model, optimizer, scheduler, loss_fn, train_loader, test_loader, device)\n",
    "\n",
    "plt.figure(figsize=(4,6))\n",
    "plt.plot(training_losses, label=\"train_loss\")\n",
    "plt.plot(testing_losses, label=\"test_loss\")\n",
    "plt.legend()\n",
    "plt.title(\"loss\")\n",
    "plt.savefig(\"Figures/SPEECHCOMMANDS_loss.png\")\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(4,6))\n",
    "plt.plot(training_accuracy, label=\"train_accuracy\")\n",
    "plt.plot(testing_accuracy, label=\"test_accuacy\")\n",
    "plt.legend()\n",
    "plt.title(\"accuracy\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cdb0b9713b2fc270c02d3719da31307603a90f79c8c7e30ea0cd7ed14dc09aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
